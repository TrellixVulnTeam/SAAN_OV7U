{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1122 14:05:37.809302 140390855927680 deprecation_wrapper.py:119] From /home/igorprotsenko/utils/models/official/transformer/model/attention_layer.py:24: The name tf.layers.Layer is deprecated. Please use tf.compat.v1.layers.Layer instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import multiprocessing\n",
    "import tables\n",
    "import tqdm\n",
    "import math\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras_radam.training import RAdamOptimizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "from transformer.model import transformer as transformer_main\n",
    "from transformer.model import model_params\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "#3rd party tool for exporting best models on validation\n",
    "from best_checkpoint_copier import *\n",
    "\n",
    "from aggregator_utils.helpers import *\n",
    "from aggregator_utils.losses import *\n",
    "from aggregator_utils import config \n",
    "from aggregator_utils.plotting_utlis import *\n",
    "from aggregator_utils.aggregator import model_fn_transformer\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer.model import transformer as transformer_main\n",
    "from transformer.model import model_params\n",
    "\n",
    "encoder_params = model_params.BASE_PARAMS\n",
    "aggregator_params = config.MIRSAAN_PARAMS\n",
    "batching_params = config.MULTI_SAMPLER_PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_params['num_hidden_layers'] = aggregator_params[\"encoder_num_hidden_layers\"]\n",
    "encoder_params['return_attention_scores'] = aggregator_params[\"encoder_return_attention_scores\"]\n",
    "encoder_params['attention_dropout']= aggregator_params[\"encoder_self_attention_dropout\"]\n",
    "encoder_params['relu_dropout'] = aggregator_params[\"encoder_relu_dropout\"]\n",
    "encoder_params['hidden_size'] = aggregator_params[\"embeddings_dim\"]\n",
    "encoder_params['use_positional_encoding']= aggregator_params[\"encoder_use_positional_encoding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTIIDENTITY_PATH = pathlib.Path('../../datasets/multiIdentity/annotations/')\n",
    "MANNOTATIONS_PATH = MULTIIDENTITY_PATH/'unioned_annotations.clsv'\n",
    "MEMBEDDINGS_PATH = MULTIIDENTITY_PATH/'unioned.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3057: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/usr/local/lib/python3.7/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "metadata = pd.read_csv(MANNOTATIONS_PATH,\n",
    "                       index_col='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tables.open_file(MEMBEDDINGS_PATH, 'r') as file:\n",
    "    data = file.root.data[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['dataset_namespace'] =  metadata.file_path.str.split('/').str[3]\n",
    "metadata.session_id = metadata.session_id.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = metadata.groupby('identity_name')\\\n",
    "               .agg({'session_id':'nunique'})\n",
    "\n",
    "identities_filtered = stats[stats.session_id>=2]\\\n",
    "                                         .index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = metadata[metadata.identity_name.isin(identities_filtered)]\n",
    "unique_identities = metadata.identity_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_identities, test_identities = train_test_split(unique_identities, test_size=.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN_CLASSES = len(train_identities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names_pd = pd.DataFrame(train_identities,\n",
    "                              columns=['identity_name'])\n",
    "eval_names_pd = pd.DataFrame(test_identities,\n",
    "                             columns=['identity_name'])\n",
    "\n",
    "for df in [train_names_pd, eval_names_pd]:\n",
    "    df['identity_reference'] = df['identity_name'].astype('category').cat.codes\n",
    "\n",
    "eval_names_pd['identity_reference'] += len(train_identities)\n",
    "names_pd = pd.concat((train_names_pd, eval_names_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = metadata.reset_index()\\\n",
    "                   .merge(names_pd, on='identity_name', how=\"left\")\\\n",
    "                   .set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_stats = metadata.groupby(['identity_name','session_id'])\\\n",
    "                         .agg({'file_path':'count'})\\\n",
    "                         .reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sessions_stats = sessions_stats[sessions_stats.identity_name.isin(train_identities)]\n",
    "eval_session_stats = sessions_stats[sessions_stats.identity_name.isin(test_identities)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions to create multi-identity video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sessions_per_identity(stats,\n",
    "                                 num_identities = batching_params['identities_limit'],\n",
    "                                 num_frames = batching_params['generated_session_len'],\n",
    "                                 metadata = metadata): \n",
    "    \n",
    "    num_identities = np.random.randint(1,\n",
    "                                       num_identities)\n",
    "    identity_lim = np.ceil(num_frames/num_identities)\n",
    "\n",
    "    \n",
    "    sessions_filtered = stats[stats.file_path>=identity_lim]\n",
    "    \n",
    "    sample_identities = np.random.choice(sessions_filtered.identity_name.unique(),\n",
    "                                         size=num_identities,\n",
    "                                         replace=False)\n",
    "    \n",
    "    filtered_sessions = sessions_filtered[sessions_filtered.identity_name.isin(sample_identities)]\n",
    "    \n",
    "    sampled_sessions = filtered_sessions.groupby('identity_name',\n",
    "                                                 group_keys=False).apply(lambda x: x.sample(1))\n",
    "    \n",
    "    retreived_indecies = metadata[metadata.session_id.isin(sampled_sessions.session_id)]\n",
    "        \n",
    "    retreived_indecies = retreived_indecies.sample(num_frames).sort_index()\n",
    "    \n",
    "    retreived_indecies[\"position\"] = retreived_indecies.groupby('identity_name', \n",
    "                                                                group_keys=False).cumcount()\n",
    "    \n",
    "    return retreived_indecies.sample(num_frames).sort_values(['identity_name','position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(stats, data=data):\n",
    "    while True:\n",
    "        video_sessions = sample_sessions_per_identity(stats)\n",
    "        embeddings = data[video_sessions.index.values]\n",
    "        labels = video_sessions.identity_reference.values\n",
    "        file_path = video_sessions.file_path.values\n",
    "        label_mask = generate_flattened_label_mask(labels)\n",
    "        yield {\"embeddings\":embeddings,\n",
    "               \"label_mask\":label_mask,\n",
    "               \"file_path\":file_path,\n",
    "               }, labels.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  (tf.float32,tf.int32, tf.uint8),\n",
    "def input_fn(gen,\n",
    "             video_length,\n",
    "             embeddings_dim):\n",
    "    binary_mask_size = video_length*(video_length-1)/2\n",
    "    return tf.data.Dataset.from_generator(lambda : gen,\n",
    "                               output_types=({'embeddings': tf.float32, 'label_mask':tf.uint8, 'file_path':tf.string}, tf.int32),      \n",
    "                               output_shapes=({'embeddings': (video_length, embeddings_dim),\n",
    "                                               'label_mask': (binary_mask_size),\n",
    "                                               'file_path':(video_length)},video_length)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGS_PATH = pathlib.Path(\"../../logs\")\n",
    "MODEL_DIR = LOGS_PATH/\"misaan\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-identity model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def misaan_model_fn(features, labels, mode, params):\n",
    "    \"\"\"\n",
    "    Model function to implement Estimator API\n",
    "    \"\"\"\n",
    "    is_training = (mode == tf.contrib.learn.ModeKeys.TRAIN)\n",
    "    is_eval = (mode == tf.contrib.learn.ModeKeys.EVAL)\n",
    "\n",
    "    if type(features) is dict:\n",
    "        embeddings = features.get(\"embeddings\")\n",
    "        binary_mask = features.get(\"label_mask\")\n",
    "        file_pathes = features.get(\"file_path\")\n",
    "        binarization_threshold = features.get('binarization_threshold',\n",
    "                                              aggregator_params['binarization_threshold'])\n",
    "        \n",
    "    with tf.name_scope(\"misaan_body\"):\n",
    "        \n",
    "        if is_training or is_eval :\n",
    "        # -- This part is valid durint EVAL and TRAIN modes --- #\n",
    "            binary_mask_full = tf_flattened_vector_to_mask(binary_mask, \n",
    "                                                           num_elements=tf.shape(embeddings)[0])\n",
    "\n",
    "            binary_mask_full = tf.cast(binary_mask_full, tf.int32)\n",
    "        else:\n",
    "            binary_mask_full = None\n",
    "    \n",
    "\n",
    "        classes_predicted_raw = tf_rule_based_class_predictor(embeddings,\n",
    "                                                              distance_threshold=binarization_threshold)\n",
    "    \n",
    "        classes_predicted = tf_flattened_vector_to_mask(classes_predicted_raw, \n",
    "                                                       num_elements= tf.shape(embeddings)[0])\n",
    "         \n",
    "        with tf.name_scope(\"mask_mixing\"):\n",
    "            \n",
    "            mask_mixed, probability_mix = componentwise_mask_mixing(binary_mask_full,\n",
    "                                                   classes_predicted,\n",
    "                                                   is_training)\n",
    "\n",
    "\n",
    "        with tf.name_scope(\"mask_postprocessing\"):\n",
    "            \n",
    "            norm_logits = tf.linalg.norm(embeddings,\n",
    "                                         axis=1)\n",
    "    \n",
    "            indecies_unique, mask_unique = tf_greedy_search_for_connected_components(mask_mixed,\n",
    "                                                                                     norm_logits)\n",
    "    \n",
    "            gt_mask_unique_rows = tf.gather(mask_unique, \n",
    "                                            indecies_unique)\n",
    "            \n",
    "            face_tracks = convert_mask_to_face_tracks(embeddings, \n",
    "                                                      gt_mask_unique_rows)\n",
    "            \n",
    "            gt_mask_unique_rows = tf.reshape(gt_mask_unique_rows,\n",
    "                                             (tf.shape(indecies_unique)[0],\n",
    "                                              tf.shape(embeddings)[0]))\n",
    "                           \n",
    "                \n",
    "            clique_size = tf.count_nonzero(gt_mask_unique_rows,\n",
    "                                           axis=1)\n",
    "            \n",
    "#             # assert that we have only fully connected components\n",
    "#              assert tf.reduce_all(tf.equal(tf.reduce_sum(gt_mask_unique_rows, axis=0),1))\n",
    "            \n",
    "            \n",
    "            num_identities_predicted = tf.size(indecies_unique)\n",
    "            \n",
    "            \n",
    "            \n",
    "        with tf.name_scope(\"aggregation\"):\n",
    "            \n",
    "            aggregated_embeddings, softmax_attention_values  = model_fn_transformer(face_tracks,\n",
    "                                                                      is_training,\n",
    "                                                                      encoder_params,\n",
    "                                                                      soft_attention = not aggregator_params['sparse_attention'],\n",
    "                                                                      component_wise = aggregator_params['component_wise_attention'])\n",
    "            \n",
    "            softmax_attention_values = tf.cast(softmax_attention_values,\n",
    "                                               tf.float64)\n",
    "            \n",
    "            aggregated_embeddings = tf.cast(aggregated_embeddings,\n",
    "                                            tf.float32)\n",
    "            \n",
    "            \n",
    "            \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "\n",
    "        predictions = {'aggregated_embeddings': aggregated_embeddings,\n",
    "#                        'binary_mask':classes_predicted,\n",
    "                       'binary_mask':gt_mask_unique_rows,  \n",
    "                       'attention_distribution': softmax_attention_values,\n",
    "                       'num_identities':num_identities_predicted,\n",
    "                       'clique_size': clique_size}\n",
    "\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    " \n",
    "            \n",
    "\n",
    "    labels_gt = tf.gather(labels, indecies_unique)\n",
    "    num_identities_real = tf.size(tf.unique(labels)[0]) \n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "\n",
    "        classes_predicted_for_acc = classes_predicted_raw\n",
    "        \n",
    "        metrics_ops = {'mask_accuracy':tf.metrics.accuracy(binary_mask,\n",
    "                                                            classes_predicted_for_acc),\n",
    "                       'mask_recall': tf.metrics.recall(binary_mask, \n",
    "                                                        classes_predicted_for_acc),\n",
    "                       \n",
    "                       'mask_precision': tf.metrics.precision(binary_mask,\n",
    "                                                              classes_predicted_for_acc),\n",
    "                       \n",
    "                       'num_identities_mae' : tf.metrics.mean_absolute_error(num_identities_real,\n",
    "                                                                             num_identities_predicted),\n",
    "                       'num_identities_predicted': tf.contrib.metrics.streaming_mean(num_identities_predicted),\n",
    "                       'num_identities_real':tf.contrib.metrics.streaming_mean(num_identities_real),\n",
    "                       }\n",
    "        \n",
    "     \n",
    "        eval_loss = tf.constant(0.)\n",
    "\n",
    "        evaluation_hooks = None\n",
    "\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=eval_loss,\n",
    "                                          eval_metric_ops = metrics_ops,\n",
    "                                          evaluation_hooks = evaluation_hooks)\n",
    "\n",
    "    if mode == tf.contrib.learn.ModeKeys.TRAIN:       \n",
    "        \n",
    "        with tf.name_scope(\"aggregation_loss\"):\n",
    "            \n",
    "            arcface_logits, positive_angles, negative_angles = get_arcface_logits(aggregated_embeddings,\n",
    "                                            labels_gt,\n",
    "                                            NUM_TRAIN_CLASSES,\n",
    "                                            s=aggregator_params['arcface_radius'],\n",
    "                                            m=aggregator_params['arcface_margin'])\n",
    "                                                                                 \n",
    "            \n",
    "            aggregation_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = labels_gt,\n",
    "                                                                    logits = arcface_logits)\n",
    "            \n",
    "            aggregation_loss = tf.reduce_mean(aggregation_loss)\n",
    "            \n",
    "        loss_overall = aggregation_loss\n",
    " \n",
    "        tf.summary.scalar('aggregation_loss', aggregation_loss)\n",
    "        tf.summary.scalar('teacher_forcing_prob', probability_mix)\n",
    "    \n",
    "        tf.summary.histogram('train_positive_angles', positive_angles)      \n",
    "        tf.summary.histogram('train_negative_angles', negative_angles)\n",
    "        tf.summary.histogram('num_identities_real', num_identities_real)\n",
    "        tf.summary.histogram('num_identities_predicted', num_identities_predicted)\n",
    "        tf.summary.histogram('predicted_class_distribution', classes_predicted)\n",
    "        tf.summary.histogram('real_class_distribution', binary_mask)\n",
    "        \n",
    "        optimizer = RAdamOptimizer(learning_rate = 1e-3)\n",
    "        \n",
    "        train_op = optimizer.minimize(\n",
    "                loss_overall, global_step=tf.train.get_global_step())\n",
    "\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss_overall, train_op=train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_receiver_fn(embeddings_dims):\n",
    "    input_images = tf.placeholder(dtype=tf.float32,\n",
    "                                     shape = embeddings_dims,\n",
    "                                     name='input_embeddings')\n",
    "    \n",
    "    binarization_threshold = tf.placeholder(dtype=tf.float32,\n",
    "                                           shape=(),\n",
    "                                           name='binarization_threshold'\n",
    "                                           )\n",
    "    # here you do all the operations you need on the images before they can be fed to the net (e.g., normalizing, reshaping, etc). Let's assume \"images\" is the resulting tensor.\n",
    "    features = {'embeddings' : input_images, \n",
    "                'binarization_threshold':binarization_threshold} # this is the dict that is then passed as \"features\" parameter to your model_fn\n",
    "    receiver_tensors = {'embeddings': input_images,\n",
    "                        'binarization_threshold':binarization_threshold} # As far as I understand this is needed to map the input to a name you can retrieve later\n",
    "    return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1122 14:08:40.383785 140390855927680 estimator.py:209] Using config: {'_model_dir': '../../logs/misaan', '_tf_random_seed': 42, '_save_summary_steps': 50, '_save_checkpoints_steps': 250, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7faddf796438>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "W1122 14:08:40.385029 140390855927680 model_fn.py:630] Estimator's model_fn (<function misaan_model_fn at 0x7fae921dbf28>) includes params argument, but params are not passed to Estimator.\n"
     ]
    }
   ],
   "source": [
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=MODEL_DIR,\n",
    "    tf_random_seed=42,\n",
    "    save_summary_steps = 50,\n",
    "    save_checkpoints_steps = 250)\n",
    "\n",
    "\n",
    "train_generator = lambda : input_fn(generate_batch(train_sessions_stats),\n",
    "                           batching_params['generated_session_len'],\n",
    "                           aggregator_params['embeddings_dim'])\\\n",
    "                          .prefetch(batching_params['prefetch_buffer'])\n",
    "\n",
    "eval_generator = lambda : input_fn(generate_batch(eval_session_stats),\n",
    "                           batching_params['generated_session_len'],\n",
    "                           aggregator_params['embeddings_dim'])\\\n",
    "                          .prefetch(batching_params['prefetch_buffer'])\n",
    "                \n",
    "    \n",
    "train_spec = tf.estimator.TrainSpec(input_fn= train_generator, max_steps = 10000)\n",
    "\n",
    "serv_func = lambda : serving_input_receiver_fn(embeddings_dims = (None, aggregator_params['embeddings_dim']))\n",
    "\n",
    "best_exporter = BestCheckpointCopier(\n",
    "   name='best_misaan', # directory within model directory to copy checkpoints to\n",
    "   checkpoints_to_keep=1, # number of checkpoints to keep\n",
    "   score_metric='num_identities_mae', # metric to use to determine \"best\"\n",
    "   compare_fn=lambda x,y: x.score > y.score, # comparison function used to determine \"best\" checkpoint (x is the current checkpoint; y is the previously copied checkpoint with the highest/worst score)\n",
    "   sort_key_fn=lambda x: x.score,\n",
    "   sort_reverse=True)\n",
    "\n",
    "final_exporter = tf.estimator.LatestExporter(\n",
    "    name='misaan_exporter', serving_input_receiver_fn=serv_func,\n",
    "    exports_to_keep=20)\n",
    "\n",
    "exporters = (best_exporter, final_exporter)\n",
    "\n",
    "\n",
    "eval_spec = tf.estimator.EvalSpec(input_fn= eval_generator,\n",
    "                                 steps= 100,\n",
    "                                 throttle_secs=30,\n",
    "                                 exporters = exporters)\n",
    "\n",
    "misaan_estimator = tf.estimator.Estimator(\n",
    "    model_fn = misaan_model_fn,\n",
    "    config = run_config,\n",
    "    params = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.estimator.train_and_evaluate(misaan_estimator, train_spec, eval_spec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "198.993px",
    "width": "499.983px"
   },
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "133.646px",
    "left": "1088.99px",
    "top": "132.715px",
    "width": "291.198px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
